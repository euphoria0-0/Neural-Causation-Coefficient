{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train Object Classifier\n",
    "\n",
    "**Model to identify causal relationships**: \n",
    "feature extraction network (ResNet18) trained on ImageNet and \n",
    "classifier network (two 512-unit hidden layers) trained on Pascal VOC 2012"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. Pascal VOC2012 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet18\n",
    "from torchvision.datasets import VOCDetection\n",
    "from torchvision import transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# object categories in pascal voc\n",
    "categories = [\n",
    "    'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', \n",
    "    'dining table', 'dog', 'horse', 'motorbike', 'person', 'potted plant', 'sheep', 'sofa', 'train', 'television'\n",
    "]\n",
    "categories = {categories[i]: i for i in range(len(categories))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: data/voc\\VOCtrainval_11-May-2012.tar\n",
      "Extracting data/voc\\VOCtrainval_11-May-2012.tar to data/voc\n"
     ]
    }
   ],
   "source": [
    "transform = T.Compose([T.Resize((224,224)), T.ToTensor()])\n",
    "dataset = VOCDetection('data/voc', image_set='train', download=True, transform=transform)\n",
    "dataloader = DataLoader(dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. Feature (ResNet) Classifier Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor():\n",
    "    model_ft = resnet18(pretrained=True)\n",
    "    # finetune\n",
    "    for param in model_ft.parameters():\n",
    "        param.requires_grad = False\n",
    "    # modify classifier\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Flatten()\n",
    "    # features = model_ft._modules.get('avgpool')\n",
    "    return model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    #  train on Pascal VOC 2012 dataset!!\n",
    "    def __init__(self, in_features=512, hidden_dim=512):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.layer1 = nn.Linear(in_features, hidden_dim)\n",
    "        self.layer2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.classifier = nn.Linear(hidden_dim, 20)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.classifier(x)\n",
    "        # softmax\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train classifier (w/ feature extractor) on Pascal VOC2012\n",
    "batch_size = 1\n",
    "num_epoch = 1\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['horse', 'person']\n"
     ]
    }
   ],
   "source": [
    "resnet = feature_extractor().to(device)\n",
    "classifier = Classifier().to(device)\n",
    "# torch.save(classifier.state_dict(), 'results/object_classifier.pt')\n",
    "\n",
    "resize_transform = T.Compose([T.Resize((224,224)), T.ToTensor()])\n",
    "\n",
    "resnet.eval()\n",
    "classifier.train()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.RMSprop(classifier.parameters())\n",
    "\n",
    "for image, anns in dataloader:\n",
    "    target, target_names = [], []\n",
    "    for obj in anns['annotation']['object']:\n",
    "        target.append(categories[obj['name'][0]])\n",
    "        target_names.append(obj['name'][0])\n",
    "        # bboxs.append(obj['bndbox'])\n",
    "\n",
    "    target = torch.tensor(target)\n",
    "    print(target_names)\n",
    "    # target = F.one_hot(torch.tensor(target), num_classes=20)\n",
    "    \n",
    "    # num_objs = len(bboxs)\n",
    "    # outputs = torch.empty((0, 20))\n",
    "    \n",
    "    # for i in range(num_objs):\n",
    "    #     objectImg = image.clone().detach()\n",
    "\n",
    "    #     bbox = bboxs[i]\n",
    "    #     mask = torch.zeros(image.shape[1:], dtype=int)\n",
    "    #     x1, x2 = int(bbox['xmin'][0]), int(bbox['xmax'][0])\n",
    "    #     y1, y2 = int(bbox['ymax'][0]), int(bbox['ymax'][0])\n",
    "    #     mask[x1:x2+1,y1:y2+1] = 1\n",
    "        \n",
    "        \n",
    "    #     mask = torch.tensor(mask>0, dtype=torch.uint8)\n",
    "        \n",
    "    #     objectImg = torch.where(mask>0, objectImg, mask.float())\n",
    "    #     objectImg = T.ToPILImage()(objectImg[0])\n",
    "        # print(objectImg.shape)\n",
    "        # objectImg = resize_transform(objectImg)\n",
    "    #     objectImg = objectImg.unsqueeze(0)\n",
    "        \n",
    "    features = resnet(image)\n",
    "    logodds = classifier(features)\n",
    "\n",
    "    #     outputs = torch.cat((outputs, logodds))\n",
    "\n",
    "    # optimizer.zero_grad()\n",
    "    # loss = criterion(outputs, target)\n",
    "    # loss.backward()\n",
    "    # optimizer.step()\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'objectImg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# objectImg = T.ToPILImage()(objectImg)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m objectImg\n",
      "\u001b[1;31mNameError\u001b[0m: name 'objectImg' is not defined"
     ]
    }
   ],
   "source": [
    "# objectImg = T.ToPILImage()(objectImg)\n",
    "objectImg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NCC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "48b1116e935963e9dfbbc6a7d059da40e2da6a2194e11fb98dfdf755c66c6cbb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
